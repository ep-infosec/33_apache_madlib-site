<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.4"/>
<title>MADlib: Elastic Net Regularization</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="../mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">MADlib
   &#160;<span id="projectnumber">1.0</span> <span style="font-size:10pt; font-style:italic"><a href="../latest/./group__grp__elasticnet.html"> A newer version is available</a></span>
   </div>
   <div id="projectbrief">User Documentation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.4 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('group__grp__elasticnet.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Elastic Net Regularization<div class="ingroups"><a class="el" href="group__grp__glm.html">Generalized Linear Models</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Collaboration diagram for Elastic Net Regularization:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<center><table><tr><td><div class="center"><iframe scrolling="no" frameborder="0" src="group__grp__elasticnet.svg" width="387" height="56"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
</td></tr></table></center>
</div>
<dl class="section user"><dt>About:</dt><dd></dd></dl>
<p>This module implements the elastic net regularization for regression problems.</p>
<p>This method seeks to find a weight vector that, for any given training example set, minimizes: </p>
<p class="formulaDsp">
\[\min_{w \in R^N} L(w) + \lambda \left(\frac{(1-\alpha)}{2} \|w\|_2^2 + \alpha \|w\|_1 \right)\]
</p>
<p> where \(L\) is the metric function that the user wants to minimize. Here \( \alpha \in [0,1] \) and \( lambda \geq 0 \). If \(alpha = 0\), we have the ridge regularization (known also as Tikhonov regularization), and if \(\alpha = 1\), we have the LASSO regularization.</p>
<p>For the Gaussian response family (or linear model), we have </p>
<p class="formulaDsp">
\[L(\vec{w}) = \frac{1}{2}\left[\frac{1}{M} \sum_{m=1}^M (w^{t} x_m + w_{0} - y_m)^2 \right] \]
</p>
<p>For the Binomial response family (or logistic model), we have </p>
<p class="formulaDsp">
\[ L(\vec{w}) = \sum_{m=1}^M\left[y_m \log\left(1 + e^{-(w_0 + \vec{w}\cdot\vec{x}_m)}\right) + (1-y_m) \log\left(1 + e^{w_0 + \vec{w}\cdot\vec{x}_m}\right)\right]\ , \]
</p>
<p> where \(y_m \in {0,1}\).</p>
<p>To get better convergence, one can rescale the value of each element of x </p>
<p class="formulaDsp">
\[ x&#39; \leftarrow \frac{x - \bar{x}}{\sigma_x} \]
</p>
<p> and for Gaussian case we also let </p>
<p class="formulaDsp">
\[y&#39; \leftarrow y - \bar{y} \]
</p>
<p> and then minimize with the regularization terms. At the end of the calculation, the orginal scales will be restored and an intercept term will be obtained at the same time as a by-product.</p>
<p>Note that fitting after scaling is not equivalent to directly fitting.</p>
<p>Right now, two optimizers are supported. The default one is FISTA, and the other is IGD. They have their own parameters, which can be specified in the <em>optimizer_params</em> as a text array. For example, 'max_stepsize = 0.1, warmup = t, warmup_lambdas = [0.4, 0.3, 0.2]'.</p>
<p><b>(1) FISTA</b></p>
<p>Fast Iterative Shrinkage Thresholding Algorithm (FISTA) [2] has the following optimizer-specific parameters: </p>
<pre class="fragment">    - max_stepsize     - default is 4.0
    - eta              - default is 2, if stepsize does not work
                        stepsize/eta will be tried
    - warmup           - default is False
    - warmup_lambdas   - default is NULL, which means that lambda
                       values will be automatically generated
    - warmup_lambda_no - default is 15. How many lambda's are used in
                       warm-up, will be overridden if warmup_lambdas
                       is not NULL
    - warmup_tolerance - default is the same as tolerance. The value
                       of tolerance used during warmup.
    - use_active_set   - default is False. Whether to use active-set
                       method to speed up the computation.
    - activeset_tolerance - default is the same as tolerance. The
                          value of tolerance used during active set
                          calculation
    - random_stepsize - default is False. Whether add some randomness
                      to the step size. Sometimes, this can speed
                      up the calculation.
</pre><p>Here, backtracking for step size is used. At each iteration, we first try the <em>stepsize = max_stepsize</em>, and if it does not work out, we then try a smaller step size <em>stepsize = stepsize / eta</em>, where <em>eta</em> must be larger than 1. At first sight, this seems to do repeated iterations for even one step, but it actually greatly increases the computation speed by using a larger step size and minimizes the total number of iterations. A careful choice of max_stepsize can decrease the computation time by more than 10 times.</p>
<p>If <em>warmup</em> is <em>True</em>, a series of lambda values, which is strictly descent and ends at the lambda value that the user wants to calculate, will be used. The larger lambda gives very sparse solution, and the sparse solution again is used as the initial guess for the next lambda's solution, which will speed up the computation for the next lambda. For larger data sets, this can sometimes accelerate the whole computation and might be faster than computation on only one lambda value.</p>
<p>If <em>use_active_set</em> is <em>True</em>, active-set method will be used to speed up the computation. Considerable speedup is obtained by organizing the iterations around the active set of featuresâ€” those with nonzero coefficients. After a complete cycle through all the variables, we iterate on only the active set till convergence. If another complete cycle does not change the active set, we are done, otherwise the process is repeated.</p>
<p><b>(2) IGD</b></p>
<p>Incremental Gradient Descent (IGD) or Stochastic Gradient Descent (SGD) [3] has the following optimizer-specific parameters: </p>
<pre class="fragment">    - stepsize         - default is 0.01
    - threshold        - default is 1e-10. When a coefficient is really
                        small, set it to be 0
    - warmup           - default is False
    - warmup_lambdas   - default is Null
    - warmup_lambda_no - default is 15. How many lambda's are used in
                        warm-up, will be overridden if warmup_lambdas
                        is not NULL
    - warmup_tolerance - default is the same as tolerance. The value
                        of tolerance used during warmup.
    - parallel         - default is True. Run the computation on
                       multiple segments or not.
</pre><p>Due to the stochastic nature of SGD, we can only obtain very small values for the fitting coefficients. Therefore, <em>threshold</em> is needed at the end of the computation to screen out those tiny values and just hard set them to be zeros. This is done as the following: (1) multiply each coefficient with the standard deviation of the corresponding feature (2) compute the average of absolute values of re-scaled coefficients (3) divide each rescaled coefficients with the average, and if the resulting absolute value is smaller than <em>threshold</em>, set the original coefficient to be zero.</p>
<p>SGD is in nature a sequential algorithm, and when running in a distributed way, each segment of the data runs its own SGD model, and the models are averaged to get a model for each iteration. This average might slow down the convergence speed, although we acquire the ability to process large datasets on multiple machines. So this algorithm provides an option <em>parallel</em> to let the user choose whether to do parallel computation.</p>
<p><b>Stopping Criteria</b> Both optimizers compute the average difference between the coefficients of two consecutive iterations, and if the difference is smaller than <em>tolerance</em> or the iteration number is larger than <em>max_iter</em>, the computation stops.</p>
<p><b>Online Help</b> The user can read short help messages by using any one of the following </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_train();</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;usage&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;predict&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;gaussian&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;binomial&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;linear&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;fista&#39;</span>);</div>
<div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;igd&#39;</span>);</div>
</div><!-- fragment --><dl class="section user"><dt>Input:</dt><dd></dd></dl>
<p>The <b>training examples</b> is expected to be of the following form: </p>
<div class="fragment"><div class="line">{TABLE|VIEW} &lt;em&gt;input_table&lt;/em&gt; (</div>
<div class="line">    ...</div>
<div class="line">    &lt;em&gt;independentVariables&lt;/em&gt;   DOUBLE PRECISION[],</div>
<div class="line">    &lt;em&gt;dependentVariable&lt;/em&gt;      DOUBLE PRECISION,</div>
<div class="line">    ...</div>
<div class="line">)</div>
</div><!-- fragment --><p>Null values are not expected.</p>
<dl class="section user"><dt>Usage:</dt><dd></dd></dl>
<p><b>Pre-run </b> Usually one gets better results and faster convergence using <em>standardize = True</em>. <b>It is highly recommended to run <em>elastic_net_train</em> function on a subset of the data with limited <em>max_iter</em> before applying it onto the full data set with a large <em>max_iter</em>. In the pre-run, the user can tweak the parameters to get the best performance and then apply the best set of parameters onto the whole data set.</b></p>
<ul>
<li>Get the fitting coefficients for a linear model:</li>
</ul>
<div class="fragment"><div class="line">SELECT {schema_madlib}.elastic_net_train (</div>
<div class="line">     <span class="stringliteral">&#39;tbl_source&#39;</span>,     -- Data table</div>
<div class="line">     <span class="stringliteral">&#39;tbl_result&#39;</span>,     -- Result table</div>
<div class="line">     <span class="stringliteral">&#39;col_dep_var&#39;</span>,    -- Dependent variable, can be an expression</div>
<div class="line">     <span class="stringliteral">&#39;col_ind_var&#39;</span>,    -- Independent variable, can be an expression or <span class="charliteral">&#39;*&#39;</span></div>
<div class="line">     <span class="stringliteral">&#39;regress_family&#39;</span>, -- <span class="stringliteral">&#39;gaussian&#39;</span> (or <span class="stringliteral">&#39;linear&#39;</span>). <span class="stringliteral">&#39;binomial&#39;</span></div>
<div class="line">                             (or <span class="stringliteral">&#39;logistic&#39;</span>) will be supported</div>
<div class="line">     alpha,            -- Elastic net control parameter, value in [0, 1]</div>
<div class="line">     lambda_value,     -- Regularization parameter, positive</div>
<div class="line">     standardize,      -- Whether to <a class="code" href="array__ops_8sql__in.html#adf90038b728d1904b03767cc79dd9561" title="Array normalization function. ">normalize</a> the data. Default: True</div>
<div class="line">     <span class="stringliteral">&#39;grouping_col&#39;</span>,   -- Group by which columns. Default: NULL</div>
<div class="line">     <span class="stringliteral">&#39;optimizer&#39;</span>,      -- Name of optimizer. Default: <span class="stringliteral">&#39;fista&#39;</span></div>
<div class="line">     <span class="stringliteral">&#39;optimizer_params&#39;</span>,-- Optimizer parameters, delimited by comma. Default: NULL</div>
<div class="line">     <span class="stringliteral">&#39;excluded&#39;</span>,       -- Column names excluded from <span class="charliteral">&#39;*&#39;</span>. Default: NULL</div>
<div class="line">     max_iter,         -- Maximum iteration number. Default: 10000</div>
<div class="line">     tolerance         -- Stopping criteria. Default: 1e-6</div>
<div class="line"> );</div>
</div><!-- fragment --><p>If <em>col_ind_var</em> is '*', then all columns of <em>tbl_source</em> will be used as features except those listed in the <em>excluded</em> string. If the dependent variable is a column name, it is then automatically excluded from the features. However, if the dependent variable is a valid Postgres expression, then the column names inside this expression are not excluded unless explicitly put into the <em>excluded</em> list. So it is a good idea to put all column names involved in the dependent variable expression into the <em>excluded</em> string.</p>
<p>The <em>excluded</em> string is a list of column names excluded from features delimited by comma. For example, 'col1, col2'. If it is NULL or an empty string '', no column is excluded.</p>
<p>If <em>col_ind_var</em> is a single column name, which is the array type, one can still use <em>excluded</em>. For example, if <em>x</em> is a column name, which is an array of size 1000, and the user wants to exclude the 100-th, 200-th and 301-th elements of the array, he can set <em>excluded</em> to be '100, 200, 301'.</p>
<p>Both <em>col_dep_var</em> and <em>col_ind_var</em> can be valid Postgres expression. For example, <em>col_dep_var = 'log(y+1)'</em>, and <em>col_ind_var = 'array[exp(x[1]), x[2], 1/(1+x[3])]'</em> etc. In the binomial case, one can set <em>col_dep_var = 'y &lt; 0'</em> etc.</p>
<p>Output: </p>
<div class="fragment"><div class="line">family | features | features_selected | coef_nonzero | coef_all | intercept | log_likelihood | standardize | iteration_run</div>
<div class="line">------------------+------------+------------+------------+--------------+-------------+--------+--------+-----------</div>
<div class="line">...</div>
</div><!-- fragment --><p>where <em>log_likelihood</em> is just the negative value of the first equation above (up to a constant depending on the data set).</p>
<ul>
<li>Get the <b>prediction</b> on a data set using a linear model: <div class="fragment"><div class="line">SELECT madlib.elastic_net_predict(</div>
<div class="line">    <span class="stringliteral">&#39;&lt;em&gt;regress_family&lt;/em&gt;&#39;</span>,  -- Response type, <span class="stringliteral">&#39;gaussian&#39;</span> (<span class="stringliteral">&#39;linear&#39;</span>) or <span class="stringliteral">&#39;binomial&#39;</span> (<span class="stringliteral">&#39;logistic&#39;</span>)</div>
<div class="line">    &lt;em&gt;coefficients&lt;/em&gt;,    -- fitting coefficients</div>
<div class="line">    &lt;em&gt;intercept&lt;/em&gt;,  -- fitting intercept</div>
<div class="line">    &lt;em&gt;independent Variables&lt;/em&gt;</div>
<div class="line">) from tbl_data, tbl_train_result;</div>
</div><!-- fragment --> The above function returns a double value for each data point. When predicting with binomial models, the return value is 1 if the predicted result is True, and 0 if the prediction is False.</li>
</ul>
<p><b>Or</b></p>
<p>(1) </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_gaussian_predict (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --><p>(2) </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_binomial_predict (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --><p>This returns 10 BOOLEAN values.</p>
<p>(3) </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_binomial_prob (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --><p>This returns 10 probability values for True class.</p>
<p><b>Or</b> The user can use another prediction function which stores the prediction result in a table. This is usefule if the user wants to use elastic net together with general cross validation function. </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_predict(</div>
<div class="line">    <span class="stringliteral">&#39;tbl_train_result&#39;</span>,</div>
<div class="line">    <span class="stringliteral">&#39;tbl_data&#39;</span>,</div>
<div class="line">    <span class="stringliteral">&#39;col_id&#39;</span>,  -- ID associated with each row</div>
<div class="line">    <span class="stringliteral">&#39;tbl_predict&#39;</span>  -- Prediction result</div>
<div class="line">);</div>
</div><!-- fragment --><dl class="section user"><dt>Examples:</dt><dd><ol type="1">
<li>Prepare an input table/view: <div class="fragment"><div class="line">CREATE TABLE en_data (</div>
<div class="line">    ind_var DOUBLE PRECISION[],</div>
<div class="line">    dep_var DOUBLE PRECISION</div>
<div class="line">);</div>
</div><!-- fragment --></li>
<li>Populate the input table with some data, which should be well-conditioned, e.g.: <div class="fragment"><div class="line">INSERT INTO lasso_data values ({1, 1}, 0.89);</div>
<div class="line">INSERT INTO lasso_data values ({0.67, -0.06}, 0.3);</div>
<div class="line">...</div>
<div class="line">INSERT INTO lasso_data values ({0.15, -1.3}, -1.3);</div>
</div><!-- fragment --></li>
<li>learn coefficients, e.g.: <div class="fragment"><div class="line">SELECT madlib.elastic_net_train(<span class="stringliteral">&#39;en_data&#39;</span>, <span class="stringliteral">&#39;en_model&#39;</span>, <span class="stringliteral">&#39;ind_var&#39;</span>, <span class="stringliteral">&#39;dep_var&#39;</span>, 0.5, 0.1,</div>
<div class="line">                                        True, <span class="stringliteral">&#39;linear&#39;</span>, <span class="stringliteral">&#39;igd&#39;</span>, <span class="stringliteral">&#39;stepsize = 0.1, warmup = t,</span></div>
<div class="line"><span class="stringliteral">                                        warmup_lambda_no=3, warmup_lambdas = [0.4, 0.3, 0.2, 0.1],</span></div>
<div class="line"><span class="stringliteral">                                        parallel=t&#39;</span>, <span class="charliteral">&#39;1&#39;</span>, 10000, 1e-6);</div>
</div><!-- fragment --> <div class="fragment"><div class="line">SELECT madlib.elastic_net_predict(family, coef_all, intercept, ind_var)</div>
<div class="line">FROM en_data, en_model;</div>
</div><!-- fragment --></li>
</ol>
</dd></dl>
<dl class="section user"><dt>Literature:</dt><dd></dd></dl>
<p>[1] Elastic net regularization. <a href="http://en.wikipedia.org/wiki/Elastic_net_regularization">http://en.wikipedia.org/wiki/Elastic_net_regularization</a></p>
<p>[2] Beck, A. and M. Teboulle (2009), A fast iterative shrinkage-thresholding algorothm for linear inverse problems. SIAM J. on Imaging Sciences 2(1), 183-202.</p>
<p>[3] Shai Shalev-Shwartz and Ambuj Tewari, Stochastic Methods for l1 Regularized Loss Minimization. Proceedings of the 26th International Conference on Machine Learning, Montreal, Canada, 2009.</p>
<dl class="section see"><dt>See Also</dt><dd>File <a class="el" href="elastic__net_8sql__in.html" title="SQL functions for elastic net regularization. ">elastic_net.sql_in</a> documenting the SQL functions. </dd></dl>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Tue Sep 10 2013 15:48:04 for MADlib by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.4 </li>
  </ul>
</div>
</body>
</html>
