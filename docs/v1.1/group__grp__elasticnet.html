<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.4"/>
<title>MADlib: Elastic Net Regularization</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="../mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">MADlib
   &#160;<span id="projectnumber">1.1</span> <span style="font-size:10pt; font-style:italic"><a href="../latest/./group__grp__elasticnet.html"> A newer version is available</a></span>
   </div>
   <div id="projectbrief">User Documentation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.4 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('group__grp__elasticnet.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Elastic Net Regularization<div class="ingroups"><a class="el" href="group__grp__glm.html">Generalized Linear Models</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Collaboration diagram for Elastic Net Regularization:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<center><table><tr><td><div class="center"><iframe scrolling="no" frameborder="0" src="group__grp__elasticnet.svg" width="387" height="56"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
</td></tr></table></center>
</div>
<div class="toc"><b>Contents</b></p>
<ul>
<li class="level1">
<a href="#about">About</a> </li>
<li class="level1">
<a href="#help">Online Help</a> </li>
<li class="level1">
<a href="#train">Usage</a> </li>
<li class="level2">
<a href="#train">Training Function</a> </li>
<li class="level3">
<a href="#optimizer">Optimizer Parameters</a> </li>
<li class="level2">
<a href="#output">Output Table</a> </li>
<li class="level2">
<a href="#predict">Prediction Function</a> </li>
<li class="level1">
<a href="#examples">Examples</a> </li>
<li class="level1">
<a href="#seealso">See Also</a> </li>
<li class="level1">
<a href="#background">Technical Background</a> </li>
<li class="level1">
<a href="#literature">Literature</a> </li>
</ul>
</div><p><a class="anchor" id="about"></a></p>
<dl class="section user"><dt>About:</dt><dd></dd></dl>
<p>This module implements elastic net regularization for linear and logistic regression problems.</p>
<p><a class="anchor" id="help"></a></p>
<dl class="section user"><dt>Online Help </dt><dd></dd></dl>
<p>View short help messages using the following statements: </p>
<pre class="fragment">-- Summary of Elastic Net Regularization
madlib.elastic_net_train()

-- Training function syntax and output table format
madlib.elastic_net_train('usage')

-- Prediction function syntax
madlib.elastic_net_train('predict')

-- Syntax for gaussian/linear model
madlib.elastic_net_train('gaussian')
madlib.elastic_net_train('linear')

-- Syntax for binomial/logistic model
madlib.elastic_net_train('binomial')
madlib.elastic_net_train('logistic')

-- Parameter formats for optimizers
madlib.elastic_net_train('fista')
madlib.elastic_net_train('igd')
</pre><p><a class="anchor" id="train"></a></p>
<dl class="section user"><dt>Training Function</dt><dd>The training function has the following format: <pre class="fragment">madlib.elastic_net_train(
    tbl_source, tbl_result, col_dep_var, col_ind_var, 
    regress_family, alpha, lambda_value, standardize, 
    grouping_col, optimizer := NULL,  
    optimizer_params := NULL, excluded := NULL, 
    max_iter := 10000, tolerance := 1e-6)
</pre></dd></dl>
<dl class="section note"><dt>Note</dt><dd>It is <b>strongly</b> <b>recommended</b> that you run <code><a class="el" href="elastic__net_8sql__in.html#a735038a5090c112505c740a90a203e83" title="Interface for elastic net. ">elastic_net_train()</a></code> on a subset of the data with a limited <em>max_iter</em> before applying it to the full data set with a large <em>max_iter</em>. In the pre-run, you can adjust the parameters to get the best performance and then apply the best set of parameters to the whole data set.</dd></dl>
<dl class="arglist">
<dt>tbl_source </dt>
<dd><p class="startdd">Text value. The name of the table containing the training data.</p>
<p class="enddd"></p>
</dd>
<dt>tbl_result </dt>
<dd><p class="startdd">Text value. Name of the generated table containing the output model.</p>
<p class="enddd"></p>
</dd>
<dt>col_dep_var </dt>
<dd><p class="startdd">Text value. An expression for the dependent variable. Both <em>col_dep_var</em> and <em>col_ind_var</em> can be valid Postgres expressions. For example, <code>col_dep_var = 'log(y+1)'</code>, and <code>col_ind_var = 'array[exp(x[1]), x[2], 1/(1+x[3])]'</code>. In the binomial case, you can use a Boolean expression, for example, <code>col_dep_var = 'y &lt; 0'</code>.</p>
<p class="enddd"></p>
</dd>
<dt>col_ind_var </dt>
<dd><p class="startdd">Text value. An expression for the independent variables. Use <code>'*'</code> to specify all columns of <em>tbl_source</em> except those listed in the <em>excluded</em> string. If <em>col_dep_var</em> is a column name, it is automatically excluded from the independent variables. However, if <em>col_dep_var</em> is a valid Postgres expression, any column names used within the expression are only excluded if they are explicitly included in the <em>excluded</em> argument. It is a good idea to add all column names involved in the dependent variable expression to the <em>excluded</em> string.</p>
<p class="enddd"></p>
</dd>
<dt>regress_family </dt>
<dd><p class="startdd">Text value. The regression type, either 'gaussian' ('linear') or 'binomial' ('logistic').</p>
<p class="enddd"></p>
</dd>
<dt>alpha </dt>
<dd><p class="startdd">Float8 value. Elastic net control parameter, value in [0, 1].</p>
<p class="enddd"></p>
</dd>
<dt>lambda_value </dt>
<dd><p class="startdd">Float8 value. Regularization parameter, positive.</p>
<p class="enddd"></p>
</dd>
<dt>standardize </dt>
<dd><p class="startdd">Boolean value. Whether to normalize the data. Setting this to True usually yields better results and faster convergence. Default: True. </p>
<p class="enddd"></p>
</dd>
<dt>grouping_col </dt>
<dd><p class="startdd">Text value. <em>Not currently implemented. Any non-NULL value is ignored.</em> An expression list used to group the input dataset into discrete groups, running one regression per group. Similar to the SQL <code>GROUP BY</code> clause. When this value is null, no grouping is used and a single result model is generated. Default value: NULL.</p>
<p class="enddd"></p>
</dd>
<dt>optimizer </dt>
<dd><p class="startdd">Text value. Name of optimizer, either 'fista' or 'igd'. Default: 'fista'.</p>
<p class="enddd"></p>
</dd>
<dt>optimizer_params </dt>
<dd><p class="startdd">Text value. Optimizer parameters, delimited with commas. The parameters differ depending on the value of <em>optimizer</em>. See the descriptions below for details. Default: NULL.</p>
<p class="enddd"></p>
</dd>
<dt>excluded </dt>
<dd><p class="startdd">Text value. A comma-delimited list of column names excluded from features. For example, <code>'col1, col2'</code>. If the <em>col_ind_var</em> is an array, <em>excluded</em> is a list of the integer array positions to exclude, for example <code>'1,2'</code>. If this argument is NULL or an empty string <code>''</code>, no columns are excluded.</p>
<p class="enddd"></p>
</dd>
<dt>max_iter </dt>
<dd><p class="startdd">Integer value. The maximum number of iterations that are allowed. Default: 10000.</p>
<p class="enddd"></p>
</dd>
<dt>tolerance </dt>
<dd>Float value. The criteria to end iterations. Both the 'fista' and 'igd' optimizers compute the average difference between the coefficients of two consecutive iterations, and when the difference is smaller than <em>tolerance</em> or the iteration number is larger than <em>max_iter</em>, the computation stops. The default is 1e-6. </dd>
</dl>
<p><a class="anchor" id="optimizer"></a> </p>
<dl class="section user"><dt>Optimizer Parameters </dt><dd>Optimizer parameters are supplied in a string containing a comma-delimited list of name-value pairs. All of these named parameters are optional, and their order does not matter. You must use the format "&lt;param_name&gt; = &lt;value&gt;" to specify the value of a parameter, otherwise the parameter is ignored.</dd></dl>
<p>When the <a class="el" href="elastic__net_8sql__in.html#a735038a5090c112505c740a90a203e83">elastic_net_train()</a> <em>optimizer</em> argument value is <b>'fista'</b>, the <em>optimizer_params</em> argument has the following format: </p>
<pre class="fragment">  'max_stepsize = ..., eta = ..., warmup = ..., warmup_lambdas = ..., 
   warmup_lambda_no = ..., warmup_tolerance = ..., use_active_set = ..., 
   activeset_tolerance = ..., random_stepsize = ...'
</pre><dl class="arglist">
<dt>max_stepsize </dt>
<dd>Initial backtracking step size. At each iteration, the algorithm first tries <em>stepsize = max_stepsize</em>, and if it does not work out, it then tries a smaller step size, <em>stepsize = stepsize/eta</em>, where <em>eta</em> must be larger than 1. At first glance, this seems to perform repeated iterations for even one step, but using a larger step size actually greatly increases the computation speed and minimizes the total number of iterations. A careful choice of <em>max_stepsize</em> can decrease the computation time by more than 10 times. The default is 4.0. </dd>
<dt>eta </dt>
<dd><p class="startdd">If stepsize does not work <em>stepsize</em> / <em>eta</em> is tried. Must be greater than 1. The default is 2.</p>
<p class="enddd"></p>
</dd>
<dt>warmup </dt>
<dd><p class="startdd">If <em>warmup</em> is True, a series of lambda values, which is strictly descent and ends at the lambda value that the user wants to calculate, is used. The larger lambda gives very sparse solution, and the sparse solution again is used as the initial guess for the next lambda's solution, which speeds up the computation for the next lambda. For larger data sets, this can sometimes accelerate the whole computation and may be faster than computation on only one lambda value. The default is False.</p>
<p class="enddd"></p>
</dd>
<dt>warmup_lambdas </dt>
<dd><p class="startdd">The lambda value series to use when <em>warmup</em> is True. The default is NULL, which means that lambda values will be automatically generated.</p>
<p class="enddd"></p>
</dd>
<dt>warmup_lambda_no </dt>
<dd><p class="startdd">How many lambdas are used in warm-up. If <em>warmup_lambdas</em> is not NULL, this value is overridden by the number of provided lambda values. The default is 15. </p>
<p class="enddd"></p>
</dd>
<dt>warmup_tolerance </dt>
<dd><p class="startdd">The value of tolerance used during warmup. The default is the same as the <em>tolerance</em> argument. </p>
<p class="enddd"></p>
</dd>
<dt>use_active_set </dt>
<dd><p class="startdd">If <em>use_active_set</em> is True, an active-set method is used to speed up the computation. Considerable speedup is obtained by organizing the iterations around the active set of features&mdash;those with nonzero coefficients. After a complete cycle through all the variables, we iterate on only the active set until convergence. If another complete cycle does not change the active set, we are done, otherwise the process is repeated. The default is False. </p>
<p class="enddd"></p>
</dd>
<dt>activeset_tolerance </dt>
<dd><p class="startdd">The value of tolerance used during active set calculation. The default is the same as <code>tolerance</code>.</p>
<p class="enddd"></p>
</dd>
<dt>random_stepsize </dt>
<dd>Whether to add some randomness to the step size. Sometimes, this can speed up the calculation. The default is False. </dd>
</dl>
<p>When the <a class="el" href="elastic__net_8sql__in.html#a735038a5090c112505c740a90a203e83">elastic_net_train()</a> <em>optimizer</em> argument value is <b>'igd'</b>, the <em>optimizer_params</em> argument has the following format: </p>
<pre class="fragment">'stepsize = ..., step_decay = ..., threshold = ..., warmup = ..., 
 warmup_lambdas = ..., warmup_lambda_no = ..., warmup_tolerance = ..., 
 parallel = ...' 
</pre><dl class="arglist">
<dt>stepsize </dt>
<dd>The default is 0.01. </dd>
<dt>step_decay </dt>
<dd>The actual setpsize used for current step is (previous stepsize) / exp(setp_decay). The default value is 0, which means that a constant stepsize is used in IGD. </dd>
<dt>threshold </dt>
<dd>When a coefficient is really small, set this coefficient to be 0. The default is 1e-10. Due to the stochastic nature of SGD, we can only obtain very small values for the fitting coefficients. Therefore, <em>threshold</em> is needed at the end of the computation to screen out tiny values and hard-set them to zeros. This is accomplished as follows: (1) multiply each coefficient with the standard deviation of the corresponding feature; (2) compute the average of absolute values of re-scaled coefficients; (3) divide each rescaled coefficient with the average, and if the resulting absolute value is smaller than <em>threshold</em>, set the original coefficient to zero. </dd>
<dt>warmup </dt>
<dd>If <em>warmup</em> is True, a series of lambda values, which is strictly descent and ends at the lambda value that the user wants to calculate, is used. The larger lambda gives very sparse solution, and the sparse solution again is used as the initial guess for the next lambda's solution, which speeds up the computation for the next lambda. For larger data sets, this can sometimes accelerate the whole computation and may be faster than computation on only one lambda value. The default is False. </dd>
<dt>warmup_lambdas </dt>
<dd>An array of lambda values to use for warmup. The default is Null. </dd>
<dt>warmup_lambda_no </dt>
<dd>The number of lambdas used in warm-up. The default is 15. If <em>warmup_lambdas</em> is not NULL, this argument is overridden by the size of the <em>warmup_lambdas</em> array. </dd>
<dt>warmup_tolerance </dt>
<dd>The value of tolerance used during warmup.The default is the same as <code>tolerance</code>. </dd>
<dt>parallel </dt>
<dd>Whether to run the computation on multiple segments. The default is True. SGD is a sequential algorithm in nature. When running in a distributed manner, each segment of the data runs its own SGD model and then the models are averaged to get a model for each iteration. This averaging might slow down the convergence speed, although we also acquire the ability to process large datasets on multiple machines. This algorithm, therefore, provides the <em>parallel</em> optionto allow you to choose whether to do parallel computation.  </dd>
</dl>
<p><a class="anchor" id="output"></a></p>
<dl class="section user"><dt>Output Table</dt><dd>The output table produced by the <a class="el" href="elastic__net_8sql__in.html#a735038a5090c112505c740a90a203e83" title="Interface for elastic net. ">elastic_net_train()</a> function has the following columns:</dd></dl>
<dl class="arglist">
<dt>family </dt>
<dd>The regression type: 'gaussian' or 'binomial'. </dd>
<dt>features </dt>
<dd>An array of the features (independent variables) passed into the analysis. </dd>
<dt>features_selected </dt>
<dd>An array of the features selected by the analysis. </dd>
<dt>coef_nonzero </dt>
<dd>Fitting coefficients for the selected features. </dd>
<dt>coef_all </dt>
<dd>Coefficients for all selected and unselected features </dd>
<dt>intercept </dt>
<dd>Fitting intercept for the model. </dd>
<dt>log_likelihood </dt>
<dd>The negative value of the first equation above (up to a constant depending on the data set). </dd>
<dt>standardize </dt>
<dd>Boolean value. Whether the data was normalized (<em>standardize</em> argument was True). </dd>
<dt>iteration_run </dt>
<dd>The number of iterations executed. </dd>
</dl>
<p><a class="anchor" id="predict"></a></p>
<dl class="section user"><dt>Prediction Function</dt><dd>The prediction function has the following format: <pre class="fragment">madlib.elastic_net_predict(                               
             '&lt;regress_family&gt;',
             coefficients,
             intercept,
             ind_var
         ) FROM tbl_result, tbl_new_source                            
</pre> The above function returns a double value for each data point. When predicting with binomial models, the return value is 1 if the predicted result is True, and 0 if the prediction is False.</dd></dl>
<dl class="arglist">
<dt>regress_family </dt>
<dd>The type of regression, either 'gaussian' ('linear') or 'binomal' ('logistic'). </dd>
<dt>coefficients </dt>
<dd>Fitting coefficients, as a DOUBLE array. </dd>
<dt>intercept </dt>
<dd>The intercept for the model. </dd>
<dt>ind_var </dt>
<dd>Independent variables, as a DOUBLE array. </dd>
<dt>tbl_result </dt>
<dd>The name of the output table from the training function. </dd>
<dt>tbl_new_source </dt>
<dd>The name of the table containing new data to predict. </dd>
</dl>
<p>There are several different formats of the prediction function:</p>
<ol type="1">
<li><div class="fragment"><div class="line">SELECT madlib.elastic_net_gaussian_predict (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --></li>
<li><div class="fragment"><div class="line">SELECT madlib.elastic_net_binomial_predict (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --> <br/>
 This returns 10 BOOLEAN values.</li>
<li><div class="fragment"><div class="line">SELECT madlib.elastic_net_binomial_prob (</div>
<div class="line">    coefficients, intercept, ind_var</div>
<div class="line">) FROM tbl_result, tbl_new_source LIMIT 10;</div>
</div><!-- fragment --> <br/>
 This returns 10 probability values for True class.</li>
</ol>
<p>Alternatively, you can use another prediction function that stores the prediction result in a table. This is useful if you want to use elastic net together with the general cross validation function. </p>
<div class="fragment"><div class="line">SELECT madlib.elastic_net_predict(</div>
<div class="line">    <span class="stringliteral">&#39;tbl_train_result&#39;</span>,</div>
<div class="line">    <span class="stringliteral">&#39;tbl_data&#39;</span>,</div>
<div class="line">    <span class="stringliteral">&#39;col_id&#39;</span>,      -- ID associated with each row</div>
<div class="line">    <span class="stringliteral">&#39;tbl_predict&#39;</span>  -- Prediction result</div>
<div class="line">);</div>
</div><!-- fragment --><p> You do not need to specify whether the model is "linear" or "logistic" because this information is already included in the result table.</p>
<p><a class="anchor" id="examples"></a></p>
<dl class="section user"><dt>Examples:</dt><dd><ol type="1">
<li>Create an input data set. <pre class="fragment">sql&gt; DROP TABLE IF EXISTS houses;
sql&gt; CREATE TABLE houses (id INT, tax INT, bedroom INT, bath FLOAT, price INT,
            size INT, lot INT);
sql&gt; COPY houses FROM STDIN WITH DELIMITER '|';
  1 |  590 |       2 |    1 |  50000 |  770 | 22100
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000
\.
</pre></li>
<li>Train the model. <pre class="fragment">sql&gt; DROP TABLE IF EXISTS houses_en;
sql&gt; SELECT madlib.elastic_net_train(  
       'houses', 'houses_en', 'price', 'array[tax, bath, size]', 
       'gaussian', 0.5, 0.1, true, null, 'fista', 
       '', 
        null, 10000, 1e-6);
</pre></li>
<li>View the resulting model. <pre class="fragment">-- Turn on expanded display to make it easier to read results.
sql&gt; \x on
sql&gt; SELECT * from houses_en;
</pre></li>
<li>Use the prediction function to evaluate residuals. <pre class="fragment">sql&gt; SELECT *, price - predict as residual FROM (
    SELECT houses.*, 
        madlib.elastic_net_predict(
            'gaussian', m.coef_nonzero, m.intercept, array[tax,bath,size]
        ) as predict
    FROM houses, houses_en m) s;
</pre></li>
</ol>
</dd></dl>
<p><a class="anchor" id="seealso"></a></p>
<dl class="section see"><dt>See Also</dt><dd>File <a class="el" href="elastic__net_8sql__in.html" title="SQL functions for elastic net regularization. ">elastic_net.sql_in</a> documenting the SQL functions. </dd>
<dd>
<a class="el" href="group__grp__validation.html">Cross Validation</a></dd></dl>
<p><a class="anchor" id="background"></a></p>
<dl class="section user"><dt>Technical Background</dt><dd></dd></dl>
<p>Elastic net regularization seeks to find a weight vector that, for any given training example set, minimizes: </p>
<p class="formulaDsp">
\[\min_{w \in R^N} L(w) + \lambda \left(\frac{(1-\alpha)}{2} \|w\|_2^2 + \alpha \|w\|_1 \right)\]
</p>
<p> where \(L\) is the metric function that the user wants to minimize. Here \( \alpha \in [0,1] \) and \( lambda \geq 0 \). If \(alpha = 0\), we have the ridge regularization (known also as Tikhonov regularization), and if \(\alpha = 1\), we have the LASSO regularization.</p>
<p>For the Gaussian response family (or linear model), we have </p>
<p class="formulaDsp">
\[L(\vec{w}) = \frac{1}{2}\left[\frac{1}{M} \sum_{m=1}^M (w^{t} x_m + w_{0} - y_m)^2 \right] \]
</p>
<p>For the Binomial response family (or logistic model), we have </p>
<p class="formulaDsp">
\[ L(\vec{w}) = \sum_{m=1}^M\left[y_m \log\left(1 + e^{-(w_0 + \vec{w}\cdot\vec{x}_m)}\right) + (1-y_m) \log\left(1 + e^{w_0 + \vec{w}\cdot\vec{x}_m}\right)\right]\ , \]
</p>
<p> where \(y_m \in {0,1}\).</p>
<p>To get better convergence, one can rescale the value of each element of x </p>
<p class="formulaDsp">
\[ x&#39; \leftarrow \frac{x - \bar{x}}{\sigma_x} \]
</p>
<p> and for Gaussian case we also let </p>
<p class="formulaDsp">
\[y&#39; \leftarrow y - \bar{y} \]
</p>
<p> and then minimize with the regularization terms. At the end of the calculation, the orginal scales will be restored and an intercept term will be obtained at the same time as a by-product.</p>
<p>Note that fitting after scaling is not equivalent to directly fitting.</p>
<p><a class="anchor" id="literature"></a></p>
<dl class="section user"><dt>Literature:</dt><dd></dd></dl>
<p>[1] Elastic net regularization. <a href="http://en.wikipedia.org/wiki/Elastic_net_regularization">http://en.wikipedia.org/wiki/Elastic_net_regularization</a></p>
<p>[2] Beck, A. and M. Teboulle (2009), A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM J. on Imaging Sciences 2(1), 183-202.</p>
<p>[3] Shai Shalev-Shwartz and Ambuj Tewari, Stochastic Methods for l1 Regularized Loss Minimization. Proceedings of the 26th International Conference on Machine Learning, Montreal, Canada, 2009. </p>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed Aug 21 2013 16:09:52 for MADlib by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.4 </li>
  </ul>
</div>
</body>
</html>
